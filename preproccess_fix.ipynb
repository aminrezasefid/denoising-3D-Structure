{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # sometimes needed to avoid mkl-service error\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger, WandbLogger\n",
    "from pytorch_lightning.plugins import DDPPlugin\n",
    "from pytorch_lightning.utilities import rank_zero_only\n",
    "import torch\n",
    "from torchmdnet.module import LNNP\n",
    "from torchmdnet import datasets, priors, models\n",
    "from torchmdnet.data import DataModule\n",
    "from torchmdnet.models import output_modules\n",
    "from torchmdnet.models.utils import rbf_class_mapping, act_class_mapping\n",
    "from torchmdnet.utils import LoadFromFile, LoadFromCheckpoint, save_argparse, number\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "import json\n",
    "import pandas as pd\n",
    "from rdkit.Chem import AllChem\n",
    "import copy\n",
    "from rdkit.Geometry import Point3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('commandline_args.txt', 'r') as f:\n",
    "    args = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aminr\\Documents\\Thesis\\pre-training-via-denoising\\preproccess_fix.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aminr/Documents/Thesis/pre-training-via-denoising/preproccess_fix.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data\u001b[39m.\u001b[39;49mdataset_maybe_noisy[\u001b[39m0\u001b[39;49m]\n",
      "File \u001b[1;32mc:\\Users\\aminr\\.conda\\envs\\pvd\\lib\\site-packages\\torch_geometric\\data\\dataset.py:199\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39misinstance\u001b[39m(idx, (\u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39minteger))\n\u001b[0;32m    195\u001b[0m         \u001b[39mor\u001b[39;00m (\u001b[39misinstance\u001b[39m(idx, Tensor) \u001b[39mand\u001b[39;00m idx\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m    196\u001b[0m         \u001b[39mor\u001b[39;00m (\u001b[39misinstance\u001b[39m(idx, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39misscalar(idx))):\n\u001b[0;32m    198\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices()[idx])\n\u001b[1;32m--> 199\u001b[0m     data \u001b[39m=\u001b[39m data \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(data)\n\u001b[0;32m    200\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n\u001b[0;32m    202\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\aminr\\.conda\\envs\\pvd\\lib\\site-packages\\torch_geometric\\transforms\\compose.py:21\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     19\u001b[0m         data \u001b[39m=\u001b[39m [transform(d) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data]\n\u001b[0;32m     20\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 21\u001b[0m         data \u001b[39m=\u001b[39m transform(data)\n\u001b[0;32m     22\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\aminr\\Documents\\Thesis\\pre-training-via-denoising\\torchmdnet\\datasets\\qm9.py:74\u001b[0m, in \u001b[0;36mQM9._filter_label\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_filter_label\u001b[39m(\u001b[39mself\u001b[39m, batch): \u001b[39m#return batch with only targets\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m     batch\u001b[39m.\u001b[39my \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39;49my[:, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_idx]\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[0;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m batch\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "data.dataset_maybe_noisy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aminr\\.conda\\envs\\pvd\\lib\\site-packages\\torch_geometric\\deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 400, val 50, test 118686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing mean and std:   0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aminr\\Documents\\Thesis\\pre-training-via-denoising\\preproccess_fix.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aminr/Documents/Thesis/pre-training-via-denoising/preproccess_fix.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m DataModule(args)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aminr/Documents/Thesis/pre-training-via-denoising/preproccess_fix.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m data\u001b[39m.\u001b[39mprepare_data()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aminr/Documents/Thesis/pre-training-via-denoising/preproccess_fix.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m data\u001b[39m.\u001b[39;49msetup(\u001b[39m\"\u001b[39;49m\u001b[39mfit\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\aminr\\.conda\\envs\\pvd\\lib\\site-packages\\pytorch_lightning\\core\\datamodule.py:384\u001b[0m, in \u001b[0;36mLightningDataModule._track_data_hook_calls.<locals>.wrapped_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m     obj\u001b[39m.\u001b[39m_has_prepared_data \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_run:\n\u001b[1;32m--> 384\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aminr\\Documents\\Thesis\\pre-training-via-denoising\\torchmdnet\\data.py:90\u001b[0m, in \u001b[0;36mDataModule.setup\u001b[1;34m(self, stage)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_dataset \u001b[39m=\u001b[39m Subset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39midx_test)\n\u001b[0;32m     89\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhparams[\u001b[39m\"\u001b[39m\u001b[39mstandardize\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m---> 90\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_standardize()\n",
      "File \u001b[1;32mc:\\Users\\aminr\\Documents\\Thesis\\pre-training-via-denoising\\torchmdnet\\data.py:169\u001b[0m, in \u001b[0;36mDataModule._standardize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m     atomref \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matomref \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhparams[\u001b[39m\"\u001b[39m\u001b[39mprior_model\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mAtomref\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# extract energies from the data\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m     ys \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([get_energy(batch, atomref) \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m data])\n\u001b[0;32m    170\u001b[0m \u001b[39mexcept\u001b[39;00m MissingEnergyException:\n\u001b[0;32m    171\u001b[0m     rank_zero_warn(\n\u001b[0;32m    172\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mStandardize is true but failed to compute dataset mean and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    173\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mstandard deviation. Maybe the dataset only contains forces.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    174\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aminr\\Documents\\Thesis\\pre-training-via-denoising\\torchmdnet\\data.py:169\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    167\u001b[0m     atomref \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matomref \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhparams[\u001b[39m\"\u001b[39m\u001b[39mprior_model\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mAtomref\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# extract energies from the data\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m     ys \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([get_energy(batch, atomref) \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m data])\n\u001b[0;32m    170\u001b[0m \u001b[39mexcept\u001b[39;00m MissingEnergyException:\n\u001b[0;32m    171\u001b[0m     rank_zero_warn(\n\u001b[0;32m    172\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mStandardize is true but failed to compute dataset mean and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    173\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mstandard deviation. Maybe the dataset only contains forces.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    174\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aminr\\.conda\\envs\\pvd\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aminr\\.conda\\envs\\pvd\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 521\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    522\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    523\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    524\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    525\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\aminr\\.conda\\envs\\pvd\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    560\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    562\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    563\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32mc:\\Users\\aminr\\.conda\\envs\\pvd\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\aminr\\.conda\\envs\\pvd\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\aminr\\.conda\\envs\\pvd\\lib\\site-packages\\torch\\utils\\data\\dataset.py:363\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    362\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[1;32m--> 363\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "File \u001b[1;32mc:\\Users\\aminr\\.conda\\envs\\pvd\\lib\\site-packages\\torch_geometric\\data\\dataset.py:199\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39misinstance\u001b[39m(idx, (\u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39minteger))\n\u001b[0;32m    195\u001b[0m         \u001b[39mor\u001b[39;00m (\u001b[39misinstance\u001b[39m(idx, Tensor) \u001b[39mand\u001b[39;00m idx\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m    196\u001b[0m         \u001b[39mor\u001b[39;00m (\u001b[39misinstance\u001b[39m(idx, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39misscalar(idx))):\n\u001b[0;32m    198\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices()[idx])\n\u001b[1;32m--> 199\u001b[0m     data \u001b[39m=\u001b[39m data \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(data)\n\u001b[0;32m    200\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n\u001b[0;32m    202\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\aminr\\.conda\\envs\\pvd\\lib\\site-packages\\torch_geometric\\transforms\\compose.py:21\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     19\u001b[0m         data \u001b[39m=\u001b[39m [transform(d) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data]\n\u001b[0;32m     20\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 21\u001b[0m         data \u001b[39m=\u001b[39m transform(data)\n\u001b[0;32m     22\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\aminr\\Documents\\Thesis\\pre-training-via-denoising\\torchmdnet\\datasets\\qm9.py:74\u001b[0m, in \u001b[0;36mQM9._filter_label\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_filter_label\u001b[39m(\u001b[39mself\u001b[39m, batch): \u001b[39m#return batch with only targets\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m     batch\u001b[39m.\u001b[39my \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39;49my[:, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_idx]\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[0;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m batch\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "data = DataModule(args)\n",
    "data.prepare_data()\n",
    "data.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
